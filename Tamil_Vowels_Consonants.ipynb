{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-dataloader-code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWa-q3j9tmS2",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5H2GSuoQVyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "import tensorflow as tf\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3pab_tX5P_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFvF_HIEHLBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num_classes=10\n",
        "_imported=False\n",
        "_loaded = False\n",
        "_trained = False\n",
        "epochs = 30\n",
        "\n",
        "# transform = None\n",
        "# train_loader = None\n",
        "# validation_loader= None\n",
        "# net  = None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqXRcv8sQfm6",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "            #image_data = image_data.view(image_data.size(0), -1)\n",
        "            \n",
        "            #image_data = image_data.reshape(64*64*3,1)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            #label=torch.stack([z1,z2])\n",
        "            label_vowels=z1\n",
        "            label_consonants=z2\n",
        "\n",
        "            return image_data, label_vowels,label_consonants\n",
        "\n",
        "        else:\n",
        "            return image_data, file_name\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT6_4D57Qmiz",
        "colab_type": "text"
      },
      "source": [
        "# Load Data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPiv76DIeC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1lafkZ1MHBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kaggleImport():\n",
        "  \n",
        "  # Import kaggle.json from google drive\n",
        "  # This snippet will output a link which needs authentication from any google account\n",
        "  from googleapiclient.discovery import build\n",
        "  import io, os\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  drive_service = build('drive', 'v3')\n",
        "  results = drive_service.files().list(\n",
        "      q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "  kaggle_api_key = results.get('files', [])\n",
        "  print(kaggle_api_key)\n",
        "  #filename = \"/content/.kaggle/kaggle.json\"\n",
        "  filename = \"/root/.kaggle/kaggle.json\"\n",
        "  os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "  request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "  fh = io.FileIO(filename, 'wb')\n",
        "  downloader = MediaIoBaseDownload(fh, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "      status, done = downloader.next_chunk()\n",
        "      print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "  os.chmod(filename, 600)\n",
        "  _imported=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3CIVHiwM-QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "  \n",
        "  # Use this command in new cell\n",
        "  #!kaggle datasets download -d stanfordu/street-view-house-numbers -w -f street-view-house-numbers.zip\n",
        "  !kaggle competitions download -c padhai-hindi-vowel-consonant-classification\n",
        "#   !kaggle competitions download -c padhai-tamil-vowel-consonant-classification\n",
        "\n",
        "\n",
        "  # Unzip the data\n",
        "  #!unzip street-view-house-numbers.zip\n",
        "  !unzip train.zip\n",
        "\n",
        "  !unzip test.zip\n",
        "  _loaded=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs1-6ampRBOD",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-xb9vWnVHo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomResizedCrop(224), \n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "#     ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.RandomResizedCrop(224), \n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "#     ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlZmaY_CVKtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "#                                         download=True, \n",
        "#                                         transform=transform_train)\n",
        "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
        "#                                         download=True, \n",
        "#                                         transform=transform_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYM_13kwVQ4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDlf5fyuhiEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=30\n",
        "train_on_gpu = torch.cuda.is_available()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "colab": {}
      },
      "source": [
        "def prepareTrainingData():\n",
        "  \n",
        "  global transform\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "  full_data = VowelConsonantDataset(\"train\",train=True,transform=transform)\n",
        "  #full_data = VowelConsonantDataset(\"../input/train/train\",train=True,transform=transform)\n",
        "  train_size = int(0.9 * len(full_data))\n",
        "  validation_size = int(0.1 * len(full_data))\n",
        "#   test_size = int(0.25 * len(full_data))\n",
        "  #temp1_size= int(0.002 * len(full_data))\n",
        "  #test_size = len(full_data) - train_size\n",
        "  #temp1, temp2 =  random_split(full_data, [temp1_size, len(full_data)-temp1_size])\n",
        "  #len(temp1)\n",
        "  train_data, validation_data= random_split(full_data, [train_size, validation_size])\n",
        "  #train_data, validation_data = random_split(temp1, [train_size, test_size])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "  validation_loader = torch.utils.data.DataLoader(validation_data, batch_size, shuffle=True)\n",
        "#   test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)\n",
        "  return transform, train_loader, validation_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "colab": {}
      },
      "source": [
        "def prepareTestData(transform):\n",
        "  \n",
        "  test_data = VowelConsonantDataset(\"test\",train=False,transform=transform)\n",
        "# ../input/train/test\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size,shuffle=False)\n",
        "  return test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCa-db1bWePh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# |dataiter = iter(train_loader)\n",
        "# images, label_vowels, labels_consonants = dataiter.next()\n",
        "# print(label_vowels.shape)\n",
        "# for i, img in enumerate(images,0):\n",
        "#   #img = images[i]\n",
        "#   print(type(img))\n",
        "#   npimg = img.numpy()\n",
        "#   print(npimg.shape)\n",
        "#   #print (label_vowels[i,0], labels[i,1])\n",
        "#   print(label_vowels[i,0])\n",
        "#   npimg = np.transpose(npimg, (1, 2, 0))\n",
        "#   print(npimg.shape)\n",
        "#   plt.figure(figsize = (1,1))\n",
        "#   plt.imshow(npimg)\n",
        "#   plt.show()\n",
        "# #images = images.view(images.size(0), -1)\n",
        "# print(images.shape)\n",
        "\n",
        "# print(label_vowels[10,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYro0sN5LwN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print (labels[:,0])\n",
        "# type(labels[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ8nM85O8jsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showImage(images):\n",
        "\n",
        "  for i, img in enumerate(images,0):\n",
        "\n",
        "    print(type(img))\n",
        "    npimg = img.cpu().numpy()\n",
        "    #print(npimg.shape)\n",
        "    #print (labels[i,0], labels[i,1])\n",
        "\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    #print(npimg.shape)\n",
        "    plt.figure(figsize = (1,1))\n",
        "    plt.imshow(npimg)\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Vh2jnVXM6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label_vowels = label_vowels.view(label_vowels.size(0),-1)\n",
        "\n",
        "# for i in range(10,20):\n",
        "#   img = images[i]\n",
        "#   print(type(img))\n",
        "#   npimg = img.numpy()\n",
        "#   print(npimg.shape)\n",
        "#   #print (labels[i,0], labels[i,1])\n",
        "#   print(label_vowels[i])\n",
        "#   npimg = np.transpose(npimg, (1, 2, 0))\n",
        "#   print(npimg.shape)\n",
        "#   plt.figure(figsize = (1,1))\n",
        "#   plt.imshow(npimg)\n",
        "#   plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKZjH7LyRIhG",
        "colab_type": "text"
      },
      "source": [
        "# Class Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG7nFlHjg4u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    torch.manual_seed(0)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(12288,1024)  ,\n",
        "        nn.LeakyReLU(), \n",
        "        nn.Linear(1024,64), \n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(64,4),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(4,10),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTVXCX7MdqRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader, net, flag):\n",
        "    total , correct, total_vowels, correct_vowels, total_consonants, correct_consonants = 0, 0, 0, 0, 0, 0\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     print(device)\n",
        "    for i,data in enumerate(dataloader,0):\n",
        "        #inputs = inputs.view(inputs.size(0), -1)\n",
        "        #label_vowels = labels[0,0]\n",
        "        inputs, label_vowels, label_consonants = data\n",
        "\n",
        "        label_vowels= label_vowels.view(label_vowels.size(0),-1)\n",
        "        label_consonants= label_consonants.view(label_consonants.size(0),-1)\n",
        "        inputs, label_vowels,label_consonants = inputs.to(device), label_vowels.to(device, dtype=torch.int64), label_consonants.to(device, dtype=torch.int64)\n",
        "#         for i, lbl in enumerate(labels,0):\n",
        "#           print(lbl)\n",
        "\n",
        "#        showImage(inputs)   \n",
        "        \n",
        "        outputs = net(inputs)\n",
        "#         for j,pred in enumerate(outputs.data,0):\n",
        "#           print(pred)\n",
        "        #_, pred = torch.max(outputs.data, 1)\n",
        "        _, pred_vowels = torch.max(outputs[0], 1)\n",
        "        _, pred_consonants = torch.max(outputs[1], 1)\n",
        "      \n",
        "#         result_arr.append(tf.strings.as_string(file_name), \"V\" * tf.strings.as_string(pred_vowels) )\n",
        "#         vowel = tf.concat(\"V\",tf.strings.as_string( pred_vowels.cpu()))    \n",
        "#         consonants = tf.concat(\"C\",tf.strings.as_string(pred_consonants.cpu()))\n",
        "#         print (\"vowel\", vowel)\n",
        "#         print (\"consonants\", consonants)\n",
        "\n",
        "#        if flag == 0:\n",
        "    \n",
        "        total_vowels += label_vowels.size(0)\n",
        "        correct_vowels += (pred_vowels == torch.max(label_vowels, 1)[1]).sum().item()\n",
        "#        else:\n",
        "        total_consonants += label_consonants.size(0)\n",
        "        correct_consonants += (pred_consonants == torch.max(label_consonants, 1)[1]).sum().item()\n",
        "    \n",
        "        total +=label_vowels.size(0)\n",
        "        pred_vowels == torch.max(label_vowels, 1)[1]\n",
        "        pred_consonants == torch.max(label_consonants,1)[1]\n",
        "        result_vowels = (pred_vowels == torch.max(label_vowels, 1)[1])\n",
        "        result_consonants =(pred_consonants == torch.max(label_consonants,1)[1])\n",
        "\n",
        "#         print(\"vowels\", pred_vowels, torch.max(label_vowels, 1)[1], result_vowels)\n",
        "#         print(\"consonants\", pred_consonants, torch.max(label_consonants, 1)[1], result_consonants)\n",
        "        \n",
        "        correct += (result_vowels & result_consonants).sum().item()\n",
        "        #correct += ((pred_vowels == torch.max(label_vowels, 1)[1]) and (pred_consonants == torch.max(label_consonants,1)[1])).sum().item()\n",
        "#         print (\"total & correct\",i, \"***\",  total, correct)\n",
        "        del inputs, label_vowels, label_consonants, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return 100 * correct_vowels / total_vowels,100 * correct_consonants / total_consonants, 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lXEArjKfNHa",
        "colab_type": "code",
        "outputId": "dd739a64-cc49-48ba-e730-f3c1b3b97242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kg6mC8O50FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(dataloader, net):\n",
        "    result_arr = []\n",
        "    file_arr=[]\n",
        "    vowel_consonant=[]\n",
        "    filename=[]\n",
        "    \n",
        "    for i,data in enumerate(dataloader,0):\n",
        "        inputs, file_name = data\n",
        "        \n",
        "\n",
        "        inputs= inputs.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, pred_vowels = torch.max(outputs[0], 1)\n",
        "        _, pred_consonants = torch.max(outputs[1], 1)\n",
        "          \n",
        "        vowel = np.char.add(np.full(pred_vowels.shape, \"V\").astype(str) , pred_vowels.cpu().numpy().astype(str))\n",
        "        consonant=np.char.add(np.full(pred_consonants.shape, \"_C\").astype(str) , pred_consonants.cpu().numpy().astype(str))\n",
        "#         np.insert(vowel_consonant,len(vowel_consonant), np.char.add(vowel,consonant))\n",
        "#         np.insert(filename,len(filename), file_name)\n",
        "        #np.concatenate((result,file_name), axis =1)\n",
        "        vowel_consonant  = np.char.add(vowel,consonant)\n",
        "        result_arr.append (vowel_consonant)\n",
        "        file_arr.append(file_name)\n",
        "    pred_list = []\n",
        "    print(\"file_arr\",file_arr)\n",
        "#     print('result_arr', result_arr)\n",
        "    \n",
        "    for sublist in result_arr:\n",
        "      for item in sublist:\n",
        "          pred_list.append(item)\n",
        "    for sublist in file_arr:\n",
        "      for item in sublist:\n",
        "          filename.append(item)\n",
        "    result =np.array([np.asarray(filename),np.asarray( pred_list)])\n",
        "    print (type(result))\n",
        "#     print(\"filename\",filename)\n",
        "#     print('pred_list', pred_list)\n",
        "    del inputs, outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3n7-IsL5rlw",
        "colab_type": "text"
      },
      "source": [
        "# CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs2KvF4c_Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),         # (N, 3, 64, 64) -> (N,  6, 56, 56)\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),  # (N, 6, 56, 56) -> (N,  6, 28, 28)\n",
        "            nn.Conv2d(6, 16, 5),        # (N, 6, 28, 28) -> (N, 16, 24, 24)  \n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2)   # (N,16, 24, 24) -> (N, 16, 12, 12)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(2704,120),         # (N, 2704) -> (N, 120)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "        self.fc_model1 = nn.Sequential(\n",
        "            nn.Linear(2704,120),         # (N, 2704) -> (N, 120)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x1 = self.fc_model(x)\n",
        "        x2= self.fc_model1(x)\n",
        "        return torch.stack([x1,x2])      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1uR4r0q_LQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet_ReLU(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet_ReLU, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),         # (N, 3, 64, 64) -> (N,  6, 56, 56)\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, stride=2),  # (N, 6, 56, 56) -> (N,  6, 28, 28)\n",
        "            nn.Conv2d(6, 16, 5),        # (N, 6, 28, 28) -> (N, 16, 24, 24)  \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, stride=2)   # (N,16, 24, 24) -> (N, 16, 12, 12)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(2704,120),         # (N, 2704) -> (N, 120)\n",
        "            nn.BatchNorm1d(120),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "        self.fc_model1 = nn.Sequential(\n",
        "            nn.Linear(2704,120),         # (N, 2704) -> (N, 120)\n",
        "            nn.BatchNorm1d(120),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x2= self.fc_model1(x)\n",
        "        x = self.fc_model(x)\n",
        "        return torch.stack([x,x2])\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6MzV1OFBAH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet_LeakyReLU(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet_LeakyReLU, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),         # (N, 3, 64, 64) -> (N,  6, 56, 56)\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool2d(2, stride=2),  # (N, 6, 56, 56) -> (N,  6, 28, 28)\n",
        "            nn.Conv2d(6, 16, 5),        # (N, 6, 28, 28) -> (N, 16, 24, 24)  \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool2d(2, stride=2)   # (N,16, 24, 24) -> (N, 16, 12, 12)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(2704,1200),         # (N, 2704) -> (N, 1200)\n",
        "            nn.BatchNorm1d(1200),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1200,600),          # (N, 1200) -> (N, 600)\n",
        "            nn.BatchNorm1d(600),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(600,200),          # (N, 600) -> (N, 200)\n",
        "            nn.BatchNorm1d(200),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(200,10)            # (N, 200)  -> (N, 10)\n",
        "        )\n",
        "        self.fc_model1 = nn.Sequential(\n",
        "            nn.Linear(2704,1000),         # (N, 2704) -> (N, 1000)\n",
        "            nn.BatchNorm1d(1000),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1000,500),         # (N, 1000) -> (N, 500)\n",
        "            nn.BatchNorm1d(500),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(500,100),         # (N, 500) -> (N, 100)\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(100,84),          # (N, 100) -> (N, 84)\n",
        "            nn.BatchNorm1d(84),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(84,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "#         self.fc_model = nn.Sequential(\n",
        "#             nn.Linear(2704,1024),         # (N, 2704) -> (N, 1200)\n",
        "#             nn.BatchNorm1d(1024),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(1024,10)          # (N, 1200) -> (N, 600)\n",
        "#         )\n",
        "#         self.fc_model1 = nn.Sequential(\n",
        "#             nn.Linear(2704,1024),         # (N, 2704) -> (N, 1000)\n",
        "#             nn.BatchNorm1d(1024),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(1024,512),         # (N, 1000) -> (N, 500)\n",
        "#             nn.BatchNorm1d(512),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(512,10)         # (N, 500) -> (N, 100)\n",
        "#         )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x2= self.fc_model1(x)\n",
        "        x = self.fc_model(x)\n",
        "        return torch.stack([x,x2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5kl69ddd73a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LoadModel(model,activation_fn, optimation_fn):\n",
        "  net=None\n",
        "  if (model == \"FF\"):\n",
        "    net=FeedForwardNetwork().to(device)\n",
        "  elif (model == \"CNN\"):\n",
        "    if (activation_fn == \"Tanh\"):\n",
        "      net=LeNet().to(device)\n",
        "    elif (activation_fn == \"ReLU\"):\n",
        "      net=LeNet_ReLU().to(device)\n",
        "    elif (activation_fn == \"LeakyReLU\"):\n",
        "      net=LeNet_LeakyReLU().to(device)\n",
        "  elif (model == \"VGG\"):\n",
        "    net = vggNet().to(device)\n",
        "  elif (model == \"ALEXNET\"):\n",
        "    net = alexNet().to(device)\n",
        "#     final_in_features = net.classifier[6].in_features\n",
        "#     mod_classifier = list(net.classifier.children())[:-1]\n",
        "#     mod_classifier.extend([nn.Linear(final_in_features, num_classes)])\n",
        "#     net.classifier = nn.Sequential(*mod_classifier)\n",
        "\n",
        "#     print(mod_classifier)\n",
        "  #loss_fn = nn.CrossEntropyLoss()\n",
        "  \n",
        "  #opt = optim.Adam(net.parameters())\n",
        "  #opt = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "  #opt=optim.RMSprop(net.parameters())\n",
        "  #opt = optim.Adagrad(net.parameters(),lr=0.5)\n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KcMYcsn_nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params(object):\n",
        "    def __init__(self, activation_fn,optim, model, epochs):\n",
        "        self.activation_fn = activation_fn\n",
        "        self.optim = optim\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8zkakwIG2wZ",
        "colab_type": "text"
      },
      "source": [
        "# Large CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "immr91VOUQRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PredictVowelsAndConsonants(args, net, train_loader, validation_loader):\n",
        "  print(args.model, args.activation_fn, args.optim)\n",
        "  \n",
        "  %%time  \n",
        "  loss1_arr = []\n",
        "  loss_epoch_arr1 = []\n",
        "  loss2_arr = []\n",
        "  loss_epoch_arr2 = []\n",
        "  max_epochs = args.epochs\n",
        "  min_loss = 1000\n",
        "\n",
        "#   opt = optim.Adam(net.parameters(),lr=0.001) #, weight_decay=1e-5 , lr=0.01 #, lr=1e-5, weight_decay=1e-5 (0.001)\n",
        "  \n",
        "  opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "#   torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)?\n",
        "  #opt = optim.SGD(net.parameters(), lr=0.1, momentum=0.6)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "#   loss_fn = nn.MultiLabelSoftMarginLoss()\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#   print(device)\n",
        "  net = net.to(device)\n",
        "  for epoch in range(max_epochs):\n",
        "\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          inputs, label_vowels, label_consonants = data\n",
        "          #showImage(inputs[i])\n",
        "          #inputs = inputs.view(inputs.size(0), -1)\n",
        "          #label_vowels = labels[0]\n",
        "          label_vowels = label_vowels.view(label_vowels.size(0),-1)\n",
        "          label_consonants = label_consonants.view(label_consonants.size(0),-1)\n",
        "          inputs, label_vowels, label_consonants = inputs.to(device), label_vowels.to(device, dtype=torch.int64),label_consonants.to(device, dtype=torch.int64)\n",
        "\n",
        "          opt.zero_grad()\n",
        "\n",
        "          outputs = net(inputs)\n",
        "#           print(\"type\", type(outputs))\n",
        "          #print(outputs[0])\n",
        "          #_, pred= torch.max(outputs.data, 1)\n",
        "          _, pred_vowels= torch.max(outputs[0], 1)\n",
        "          _, pred_consonants= torch.max(outputs[1], 1)\n",
        "          #print(\"max\", pred,  torch.max(labels, 1)[1])\n",
        "          #loss = loss_fn(outputs, torch.max(label_vowels, 1)[1]) #+ loss_fn(outputs, torch.max(label_consonants, 1)[1])\n",
        "          \n",
        "#           print (\"output shape\", outputs[0].shape)\n",
        "#           print(\"inputs shape\", inputs.shape)\n",
        "#           print(\"labes shape\", label_vowels.shape, label_consonants.shape)\n",
        "#           print (\"label\",  outputs[0], torch.max(label_vowels, 1)[1])\n",
        "          loss1 = loss_fn(outputs[0], torch.max(label_vowels, 1)[1]) \n",
        "          loss2 = loss_fn(outputs[1], torch.max(label_consonants, 1)[1])\n",
        "          loss = loss1 + loss2\n",
        "          #print(loss1, loss2, loss)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "#           if min_loss > loss.item():\n",
        "#             min_loss = loss.item()\n",
        "#             best_model = copy.deepcopy(net.state_dict())\n",
        "#             print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "          loss1_arr.append(loss1.item())       \n",
        "          loss2_arr.append(loss2.item())       \n",
        "          del inputs, label_vowels, label_consonants, outputs\n",
        "          torch.cuda.empty_cache()\n",
        "        \n",
        "      loss_epoch_arr1.append(loss1.item())\n",
        "      loss_epoch_arr2.append(loss2.item())\n",
        "      \n",
        "      \n",
        "#       net.load_state_dict(best_model)\n",
        "      \n",
        "      training_accuracy_score = evaluation(train_loader,net,0)\n",
        "      validation_accuracy_score = evaluation(validation_loader,net,0)\n",
        "      \n",
        "      \n",
        "      print('Epoch: %d/%d, Overall Train acc: %0.2f,Overall Validation acc: %0.2f' % (epoch, max_epochs,training_accuracy_score[2],validation_accuracy_score[2]))\n",
        "  plt.figure()\n",
        "  plt.subplot(211)\n",
        "  plt.plot(loss_epoch_arr1)\n",
        "\n",
        "  plt.subplot(212)\n",
        "  \n",
        "  plt.plot(loss_epoch_arr2)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_65Wp8P4r0",
        "colab_type": "code",
        "outputId": "e4812063-a57f-44a1-cdf0-4dfdcc04360f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchvision import models\n",
        "vgg = models.vgg16_bn(pretrained=True) #(pretrained=True)\n",
        "print(vgg)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aNO6-54udy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhgbwE1YHGx3",
        "colab_type": "code",
        "outputId": "977ddb5a-1916-4ac3-8546-f925f90d2df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "new_classifier = nn.Sequential(*list(vgg.classifier.children())[:-7])\n",
        "vgg.classifier = new_classifier\n",
        "print(vgg)\n",
        "vgg= vgg.to(device)\n",
        "# final_in_features = vgg.classifier[6].in_features\n",
        "# vgg.classifier[6] = nn.Linear(final_in_features, num_classes)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8iDAguyrQDI",
        "colab_type": "code",
        "outputId": "25973b8e-04d1-4cdd-d3eb-4e38249d3511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "print(vgg)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVHJ_ZPOzlRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LinearNet, self).__init__()\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(25088,12288),         # (N, 2704) -> (N, 1200)\n",
        "            nn.BatchNorm1d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(12288,4096),         # (N, 2704) -> (N, 1200)\n",
        "            nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(4096,1024)         # (N, 2704) -> (N, 1200)\n",
        "            \n",
        "        )\n",
        "        self.fc_model1 = nn.Sequential(\n",
        "              nn.Linear(1024,10)\n",
        "#             nn.Linear(1024,512),         # (N, 1000) -> (N, 500)\n",
        "#             nn.BatchNorm1d(512),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(512,256),         # (N, 500) -> (N, 100)        \n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(256,128),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(128,10)\n",
        "        )\n",
        "        self.fc_model2 = nn.Sequential(\n",
        "              nn.Linear(1024,512),\n",
        "              nn.BatchNorm1d(512,eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.LeakyReLU(),\n",
        "              nn.Linear(512,256),\n",
        "              nn.BatchNorm1d(256,eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.LeakyReLU(),\n",
        "              nn.Linear(256,128),\n",
        "              nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "              nn.Dropout(0.2),\n",
        "              nn.LeakyReLU(),\n",
        "              nn.Linear(128,10)\n",
        "# #             nn.Linear(1024,1024),          # (N, 1200) -> (N, 600)\n",
        "#             nn.BatchNorm1d(1024),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(1024,512),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(512,128),\n",
        "#             nn.LeakyReLU(),\n",
        "#             nn.Linear(128,10)\n",
        "\n",
        "        )\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVipxV1rpfGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class vggNet(LinearNet):\n",
        "    def __init__(self): \n",
        "        super(vggNet, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = vgg(x)\n",
        "#         x1.requires_grad\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        \n",
        "#         x1 = self.fc_model2(x1)\n",
        "#         x2 = vgg(x)\n",
        "#         x2 = x2.view(x2.size(0), -1)\n",
        "        x2= self.fc_model2(x)\n",
        "        x= self.fc_model1(x)\n",
        "        return torch.stack([x,x2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRFsmXKi155c",
        "colab_type": "code",
        "outputId": "c3cd077a-aa85-406d-926e-a1992ac039f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "print(alexnet)\n",
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "new_classifier = nn.Sequential(*list(alexnet.classifier.children())[:-7])\n",
        "alexnet.classifier = new_classifier\n",
        "print(alexnet)\n",
        "alexnet= alexnet.to(device)\n",
        "print(alexnet)    "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Dropout(p=0.5)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential()\n",
            ")\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LzJU4QW2L4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearAlexNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LinearAlexNet, self).__init__()\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(9216,4096),         # (N, 2704) -> (N, 1200)\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(4096,1024),         # (N, 2704) -> (N, 1200)\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.fc_model1 = nn.Sequential(\n",
        "            nn.Linear(1024,512),         # (N, 1000) -> (N, 500)\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512,10)         # (N, 500) -> (N, 100)        \n",
        "        )\n",
        "        self.fc_model2 = nn.Sequential(\n",
        "            nn.Linear(1024,10)          # (N, 1200) -> (N, 600)\n",
        "        )        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA9e5C8n1waq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class alexNet(LinearAlexNet):\n",
        "    def __init__(self): \n",
        "        super(alexNet, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = alexnet(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        x2= self.fc_model1(x)\n",
        "        x = self.fc_model2(x)\n",
        "        return torch.stack([x,x2])     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOPqAy0RTLbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainModel(_imported, _loaded):\n",
        "  global net\n",
        "  if (not _imported):\n",
        "    kaggleImport()\n",
        "  if (not _loaded):\n",
        "    loadData()\n",
        "  transform, train_loader, validation_loader = prepareTrainingData()\n",
        "  \n",
        "  args= Params(\"LeakyReLU\", \"Adam\", \"VGG\", epochs)\n",
        "  net = LoadModel(args.model, args.activation_fn, args.optim)\n",
        "  PredictVowelsAndConsonants(args,net, train_loader, validation_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kNxJ4OCeVtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictOutput():\n",
        "  test_loader = prepareTestData(transform)\n",
        "  \n",
        "  print(test_loader, transform)\n",
        "  result_arr = predict(test_loader,net)\n",
        "  \n",
        "  print(result_arr[0])\n",
        "  submission = pd.DataFrame({'ImageId':result_arr[0], 'Class':[0]*result_arr[0].size})\n",
        "  submission = submission[['ImageId', 'Class']]\n",
        "  submission['Class'] = result_arr[1]\n",
        "  submission.to_csv(\"submission.csv\", index=False)\n",
        "  # submission.groupby('Class').size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSq7Wj_mvr2N",
        "colab_type": "text"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJahWCstvuf8",
        "colab_type": "code",
        "outputId": "895e6165-d611-4745-8b0d-ecf737eb9864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        }
      },
      "source": [
        "trainModel(True, True)\n",
        "# print(_imported)      "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG LeakyReLU Adam\n",
            "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
            "Wall time: 6.2 µs\n",
            "Epoch: 0/30, Overall Train acc: 3.34,Overall Validation acc: 2.50\n",
            "Epoch: 1/30, Overall Train acc: 4.08,Overall Validation acc: 4.00\n",
            "Epoch: 2/30, Overall Train acc: 5.84,Overall Validation acc: 5.10\n",
            "Epoch: 3/30, Overall Train acc: 6.62,Overall Validation acc: 6.50\n",
            "Epoch: 4/30, Overall Train acc: 7.37,Overall Validation acc: 5.50\n",
            "Epoch: 5/30, Overall Train acc: 8.38,Overall Validation acc: 6.50\n",
            "Epoch: 6/30, Overall Train acc: 8.94,Overall Validation acc: 6.40\n",
            "Epoch: 7/30, Overall Train acc: 9.10,Overall Validation acc: 7.80\n",
            "Epoch: 8/30, Overall Train acc: 9.78,Overall Validation acc: 9.90\n",
            "Epoch: 9/30, Overall Train acc: 10.97,Overall Validation acc: 8.00\n",
            "Epoch: 10/30, Overall Train acc: 11.97,Overall Validation acc: 8.50\n",
            "Epoch: 11/30, Overall Train acc: 11.63,Overall Validation acc: 9.80\n",
            "Epoch: 12/30, Overall Train acc: 12.43,Overall Validation acc: 9.20\n",
            "Epoch: 13/30, Overall Train acc: 13.40,Overall Validation acc: 11.10\n",
            "Epoch: 14/30, Overall Train acc: 13.68,Overall Validation acc: 9.20\n",
            "Epoch: 15/30, Overall Train acc: 14.74,Overall Validation acc: 11.30\n",
            "Epoch: 16/30, Overall Train acc: 15.12,Overall Validation acc: 11.90\n",
            "Epoch: 17/30, Overall Train acc: 15.98,Overall Validation acc: 11.50\n",
            "Epoch: 18/30, Overall Train acc: 16.43,Overall Validation acc: 12.10\n",
            "Epoch: 19/30, Overall Train acc: 17.44,Overall Validation acc: 10.50\n",
            "Epoch: 20/30, Overall Train acc: 18.14,Overall Validation acc: 12.10\n",
            "Epoch: 21/30, Overall Train acc: 18.14,Overall Validation acc: 12.00\n",
            "Epoch: 22/30, Overall Train acc: 18.33,Overall Validation acc: 12.30\n",
            "Epoch: 23/30, Overall Train acc: 18.64,Overall Validation acc: 13.60\n",
            "Epoch: 24/30, Overall Train acc: 19.36,Overall Validation acc: 11.70\n",
            "Epoch: 25/30, Overall Train acc: 19.40,Overall Validation acc: 13.10\n",
            "Epoch: 26/30, Overall Train acc: 22.20,Overall Validation acc: 13.40\n",
            "Epoch: 27/30, Overall Train acc: 21.38,Overall Validation acc: 12.30\n",
            "Epoch: 28/30, Overall Train acc: 22.77,Overall Validation acc: 13.50\n",
            "Epoch: 29/30, Overall Train acc: 22.94,Overall Validation acc: 14.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5lVmUDN4zYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictOutput()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_8tfBiVzVBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}